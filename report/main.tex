\documentclass[11pt,a4paper]{article}

\usepackage{graphicx}
%\usepackage[german]{babel}
\usepackage[utf8]{inputenc}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[amsmath,amsthm,thmmarks]{ntheorem}
\usepackage{array}
\usepackage{stmaryrd}
\usepackage{scrpage2} 
\usepackage{color}
\usepackage{bm}
\usepackage{varioref}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{tikz}
\usetikzlibrary{shapes.misc} 

\usepackage{geometry}
\usepackage{mathrsfs}

\usepackage{scalerel}
\usepackage[usestackEOL]{stackengine}
\def\dashint{\,\ThisStyle{\ensurestackMath{%
			\stackinset{c}{.2\LMpt}{c}{.5\LMpt}{\SavedStyle-}{\SavedStyle\phantom{\int}}}%
		\setbox0=\hbox{$\SavedStyle\int\,$}\kern-\wd0}\int}

\newtheorem{defi}{Definition}%[section]
\newtheorem{satz}{Theorem}%[section]
\newtheorem{lemma}{Lemma}%[section]
\newtheorem{rmk}{Remark}%[section]

\usepackage[T1]{fontenc}
\usepackage{scrpage2}

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\numberwithin{equation}{section}
\begin{document}
	
\thispagestyle{empty}
	
\begin{center}
\begin{minipage}{\textwidth}
			\vspace{0.5cm}
			\centering
			\Huge{\textbf{-Project 1-\\A Computational Study of the Ground-State Energy for Bosonic N-Particle Systems }} \\ 
			\vspace{2cm}
			\includegraphics[width=.4\textwidth]{uio}\\
			\vspace{2cm}
			\Huge
			\vspace{0cm}
			Yngve  Mardal Moe\\
			\begin{large}Norges Milj√∏- og Biovitenskapelige Universitet\end{large}\\
			Fabian Maximilian Faulstich\\
			\begin{large}Universitetet i Oslo\end{large}\\
			\vspace{1.5cm}
			\Huge
			Teacher: Prof. Dr. Morten Hjorth-Jensen\\
			
\end{minipage}
\end{center}
		
\cleardoublepage
\thispagestyle{empty}
\quad
\newpage
\thispagestyle{empty}

% Abstract: 
%It should be accurate and informative. 
%Remember to state your main findings here. If there are specific
%results you have obtained, they should be stated here.
%Total number of possible points: 5
\begin{minipage}{0.9\textwidth}
\vspace{5cm}
\begin{center}
\Huge{Abstract}
\end{center}
Here comes the abstract...
\end{minipage}
\cleardoublepage
\thispagestyle{empty}
\quad
\newpage
\thispagestyle{empty}

\pagebreak
\tableofcontents
\listoffigures
\listoftables
\thispagestyle{empty} 

\pagebreak
\setcounter{page}{1}
% Introduction: 
%Here you motivate the reader, give a status of the problem(s) and 
%the major objectives. State what you have done and give an outline
%of the report.
%Total number of possible points: 10
\section{Introduction}
%
%
It was more than 80 years ago that Paul Dirac made his famous statement:

{\it The underlying physical laws necessary for the mathematical theory of a large part of physics and the whole of chemistry are [...] completely known~\cite{dirac1929quantum}.} 

However, the development of {\it approximate practical methods of applying quantum mechanics}, demanded by Dirac in the same breath, is still a highly active field of research intersecting physics, chemistry, applied mathematics and computer science. 
%
In order to obtain results that can be utilized in practice, an extremely high accuracy of such practical methods is needed.
%
On the other hand, solving the governing equation of quantum mechanics, the molecular Schr\"odinger equation, is an exceedingly high-dimensional and thus computationally demanding problem.
%
Due to this very unfortunate combination of demanded high accuracy on the one side and the computational bad scaling on the other, small to medium-sized quantum chemical problems are still pushing the limits of commonly available computational resources.

%
In this project we focus on $N$-particle bosonic systems, i.e., particles that follow {\it Bose--Einstein statistics}.
%
We present a computational study of the system's ground-state energy using statistical methods. 
%
This work is outlined as follows:

%
We start by introducing the considered bosonic system in a more detailed, and for our approaches suitable, way in Section 2. 
%
We describe the quantum mechanical model we use to quantify hard sphere Bose gas in an elliptic trap (this covers in particular the special case of a spherical trap). 
%
In Section 3 we present the Monte Carlo method and the used statistical tools in a formal and mathematical rigorous way.
%
We introduce Markov processes, in discrete and continuous time, as the mathematical concept on which we build the Monte Carlo method and two sampling methods, namely, the metropolis sampling and the importance sampling. 
%
The later will make excessive use of the Fokker--Planck and the Langevin equation. 
%
As the focus of this work is on a computational study, we do not introduce the concept of stochastic differential equations, however, we present a {\it quick and dirty} derivation of the Fokker--Planck equation via the {\it Kramers--Moyal} expansion.
%
To present our computed data with a proper evaluation of the statical errors we introduce the {\it Bootstrap} and the {\it Blocking} method.
%
In Section 4 we present the implementation used in this project. 
%
We hereby follow the project description, starting with deriving analytic expressions for the {\it local energy} in different potentials.
%
In Section 5 we present our numerical results. 


\section{The Hard Sphere Bose Gas' Quantum Mechanical Model} 
%
The aim of this project is to evaluate the ground state energy of a trapped, hard sphere Bose gas for different numbers of particles considering a specific trial wave function $\psi_T$.
%
This trial wave function is used to study the sensitivity of condensate and non-condensate properties to the hard sphere radius and the number of particles.  
%
We start this section by introducing the quantum mechanical model used to describe a trapped hard sphere Bose Gas.
%
Note that this model involves a {\it formal error}, i.e., an error that follows from not knowing the exact theory to describe the physical behavior of atomic and subatomic particles. 
%
  

\subsection{The Trapped Hard Sphere Bose Gas}
%
In this work we study the ground state energy of a trapped, hard sphere Bose gas, i.e., a gas composed of bosons, which have an integer value of spin and obey {\it Bose--Einstein statistics}.
%
The trap we use in this project is a {\it spherical} (S) or an {\it elliptical} (E) harmonic trap in one, two and finally three dimensions, with the latter given by
\begin{equation}
V_{ext}(r) = 
\Bigg\{
\begin{array}{ll}
\frac{1}{2}m\omega_{ho}^2r^2 & (S)~,\\
\strut
\frac{1}{2}m[\omega_{ho}^2(x^2+y^2) + \omega_z^2z^2] & (E)~.
\label{trap_eqn}
\end{array}
\end{equation}
The considered two-body Hamiltonian is formally defined by
\begin{equation}
H\psi(r) = \sum_i^N \left(\frac{-\hbar^2}{2m}{\nabla }_{i}^2 +V_{ext}({{r}}_i)  +
\sum_{i<j}^{N} V_{int}({{r}}_i,{{r}}_j)\right)\psi(r)~,
\end{equation}
where $\omega_{ho}^2$ defines the {\it trap potential strength} and $r = (r_1,...,r_N)$.  
%
In the case of the elliptical trap, $\omega_{ho}$ is the trap frequency in the {\it perpendicular plane}, i.e., the $x$-$y$-plane, and $\omega_z$ is the frequency in the $z$-direction.  
%
We represent the boson's interaction by a pairwise, repulsive potential
\begin{equation}
V_{int}(|{r}_i-{r}_j|) =  \Bigg\{
\begin{array}{ll}
\infty & {|{r}_i-{r}_j|} \leq {a}~,\\
0 & {|{r}_i-{r}_j|} > {a}~,
\end{array}
\end{equation}
where $a$ is the so-called {\it hard-core diameter} of the bosons.
%
This potential describes non-interacting bosons modeled as hard spheres of radius $a/2$ described as point mass at position $r_i$, i.e., the distance of two bosons positioned at $r_i$ and $r_j$ can not be smaller than $a$.   
%
Consequently, $V_{int}(|{r}_i-{r}_j|)$ is zero if the bosons are separated by a distance $|{r}_i-{r}_j|$ greater than $a$ but infinite if they attempt to come within a distance $|{r}_i-{r}_j| \leq a$, i.e., their volumes overlap.

\subsection{The Trial Function}
%
%
The trial wave function is used to study the sensitivity of condensate and non-condensate properties to the hard sphere radius and the number of particles.
%
For the ground state with $N$ atoms it s given by

\begin{equation}
\psi_T({r})=\psi_T({r}_1, {r}_2, \dots {r}_N,\alpha,\beta)=\prod_i g(\alpha,\beta,{r}_i)\prod_{i<j}f(a,|{r}_i-{r}_j|)~,
\label{eq:trialwf}
\end{equation}
where $\alpha$ and $\beta$ are variational parameters. 
%
The single-particle wave function $g$ is proportional to the harmonic oscillator function for the ground state, i.e.,
\begin{equation}
g(\alpha,\beta,{r}_i)= \exp(-\alpha(x_i^2+y_i^2+\beta z_i^2))~.
\end{equation}
The mean square vibrational amplitude of a single boson at $T=0K$ in the trap (\ref{trap_eqn}) is $\langle x^2\rangle=\hbar/2m\omega_{ho}$ so that $a_{ho} \equiv (\hbar/m\omega_{ho})^{\frac{1}{2}}$ defines the characteristic length of the trap.  
%
For spherical traps we set $\beta = 1$ and for non-interacting bosons we have $\alpha = 1/2a_{ho}^2$, setting $a = 0$.
%
%The ratio of the frequencies is denoted $\lambda=\omega_z/\omega_{\perp}$ leading to a ratio of the trap lengths $(a_{\perp}/a_z)=(\omega_z/\omega_{\perp})^{\frac{1}{2}} = \sqrt{\lambda}$.
%
The {\it correlation wave function} is given by

\begin{equation}
f(a,|{r}_i-{r}_j|)=\Bigg\{
\begin{array}{ll}
0 & \text{, for }{|{r}_i-{r}_j|} \leq {a}~,\\
(1-\frac{a}{|{r}_i-{r}_j|}) & \text{, for }{|{r}_i-{r}_j|} > {a}~.
\end{array}
\end{equation}




% Formalism/methods: 
%Here you discuss the methods used and their basis/suitability.  Give a presentation of the algorithm(s), possible
%errors etc etc. 
%Total number of possible points: 20
\section{Variational Monte Carlo Method and Statistical Analysis}
%
%
%
One of the main challenges in computational physics lies in the high dimensionality of the considered problems. 
%
To illustrate this we consider a single water molecule reduced to the electronic problem by the Born--Oppenheimer approximation \cite{slater1964quantum,born1927quantentheorie}.
%
The spacial discretization of this three-dimensional ten-electron problem is in $\mathcal{O}(n^{30})$, where $n$ describes the discretization points. 
%
Hence, for a rough discretization of $n=10^3$ the storage of this simple molecule already exceeds the estimated number of particles in the universe. 
%
This exponential growth with respect to the dimensionality is also known as \textit{curse of dimensionality}. 
%
Subsequently, we introduce computational methods breaking this fatal growth behavior. 



\subsection{Variational Monte Carlo Method}
%
%
The main object of study will be the system's energy, by means of the {\it Copenhagen interpretation} \cite{heisenberg1963kopenhager}, given by the Hamilton operator's expectation value, i.e.,
\begin{align*}
\langle H \rangle_{\psi} = \frac{\int_{\Omega}\psi^*(R) H \psi(R)\, dR}{\Vert \psi \Vert}~.
\end{align*}
We emphasize that in most cases $\Omega$ will be high dimensional, e.g., for nuclear problems $\Omega = \mathbb{R}^{3N}\times \{\pm 1/2\}^{N} \times \{\pm 1/2\}^{N}$ describing the spacial-, spin- and isospin-coordinates of the nucleons. 
%
This high dimensionality prohibits a use of conventional numerical integration schemes like the Gaussian quadrature.
%
There are various alternative many-body methods trying to break the curse of dimensionality, however, their success depends strongly on the system's physical properties.

%
The method chosen for this work is the {\it variational Monte-Carlo method} (vmc). Before going into further detail, we notice that the system's energy is defined by the Rayleigh--Ritz variational principle \cite{yserentant2013short}, i.e.,
\begin{align*}
E_0 = \underset{\Vert \psi \Vert=1}{\mathrm{min}}\langle \psi ,H \psi\rangle=\langle H \rangle_{\psi_0} ~.
\end{align*} 
Hence, by choosing any trial wave function $\psi_T$ with $\Vert \psi_T\Vert =1$ we get $E_0\leq \langle H \rangle_{\psi_T }$.
%
Using special properties of the Hamilton operator\footnote{
Careful, linear self-adjoint and bounded operators do not necessarily have an eigen-basis. However, in finite dimensional Hilbert spaces (as relevant for computations) this is always true.
} we can expand any trial function in terms of eigenstates, i.e.,
\begin{align*}
\psi_T=\sum_{i}a_i\psi_i~,
\end{align*}
with $H\psi_i = E_i \psi_i$.
%
Without loss of generality we assume $\Vert \psi \Vert = 1$ which implies
\begin{align*}
E_0\leq \frac{\sum_{i}|a_i|^2E_i}{\sum_{i}|a_i|^2}~.
\end{align*}
We see that by varying the trial function's parameters $\{a_i\}$, the Rayleigh--Ritz variational principle yields the ground state solution.
%
Note, that in most cases the wave function has small extension coefficients in large parts of the configuration space, i.e., a straightforward computation using homogeneously distributed points in the configuration space will most likely not be efficient.  
%
Consequently, we will use the \textit{importance sampling} combined with the \textit{Metropolis} algorithm.

%
Subsequently we describe the underlying theory of Monte Carlo methods, which will be sued in this project.
%
Monte-Carlo methods are based on the \textit{strong law of large numbers}:\\

\textit{
\textbf{Etemadi, 1981 \cite{etemadi1981elementary}:} Let $(X_n)_{n\in\mathbb{N}}\subseteq L^1(\Omega, \mathcal{A}, \mathbb{P})$ be a sequence of pairwise independent, identically distributed random variables. Then
\begin{align*}
\frac{1}{N}\sum_{n=1}^NX_n\overset{a.s}{\longrightarrow}\mathbb{E}(X_1)~,
\end{align*}
as $n\to \infty$.
}

\begin{rmk}
In the above theorem, we used the standard notation for probability theory:
%
The function space $L^1(\Omega, \mathcal{A}, \mathbb{P})$ is the quotient space with respect to the kernel of the  ${L^1}$-norm of reel-valued $\mathbb{P}$-integrable functions $f:\Omega \to \mathbb{R}$ with the underlying sigma-algebra $\mathcal{A}$.\\
Almost sure convergence or strong convergence, denoted by $\overset{a.s}{\longrightarrow}$, means that
\begin{align*}
\mathbb{P}\left( \lim_{N\to \infty}X_n -  \mathbb{E}(X_1)\right)=0~,
\end{align*}
i.e., the set on which $\lim_{N\to \infty}X_n$ differs from $\mathbb{E}(X_1)$ is of $\mathbb{P}$-measure zero.\\
The above cited version is a stronger version of the \textit{strong law of large numbers} proven by Kolmogorov in 1930 \cite{kolmogorov1930loi} as it only presumes pairwise independence of the random variables. 
\end{rmk}

For a chosen trial function $\psi_T(R;a)=\sum_{i}a_i\psi_i(R)$ we define the probability density function 
\begin{align*}
P(R;a) = \frac{|\psi_T(R;a)|^2}{\Vert \psi_T(\cdot\;;a)\Vert}
\end{align*} 
and observe that 
\begin{align*}
\langle H \rangle_{\psi_T(\cdot\;;a)} 
&= \int_{\Omega}\frac{\psi_T(R;a)^*H\psi_T(R;a)}{\Vert \psi_T(\cdot\;;a)\Vert}\,dR
=\int_{\Omega} \frac{|\psi_T(R;a)|^2}{\Vert \psi_T(\cdot\;;a)\Vert}\frac{H\psi_T(R;a)}{\psi_T(R;a)}\,dR\\
&=\int_{\Omega} P(R;a)E_L(R;a)\,dR~,
\end{align*}
where $E_L(R;a) = H\psi_T(R;a)/\psi_T(R;a)$ denotes the {\it local energy}. 
%
We see that the last term corresponds to an integration with respect to the probability measure $\mathbb{P}$ induced by the density $P$.
%
By \textbf{Etemadi} this yields
\begin{equation}
\label{eq:StrongLawofBN}
\frac{1}{N}\sum_{n=1}^NP(R_i;a)E_L(R_i;a)\overset{a.s}{\longrightarrow}\langle H \rangle_{\psi_T(\cdot\;;a)}~.
\end{equation}
We emphasize, that in the setting of Monte--Carlo methods, the number of pairwise identically distributed, independent variables $N$ corresponds to the number of  Monte--Carlo samples.\\
\\
GO INTO DETAILS, HOW OUR COMPUTATIONS WORK!!!\\
MENTION THE VARIANCE = 0\\
\\


\subsubsection{Metropolis Sampling}
%
%
We start with a so-called brute-force sampling using the \textit{metropolis sampling}, i.e., sampling based on the Metropolis--Hastings algorithm \cite{metropolis1953equation,hastings1970monte}.
%
As workhorse of {\it Markov-Chain Monte--Carlos methods}, the Metropolis--Hastings algorithm (also called Metropolis algorithm) is based on the following described theory of {\it Markov chains}.
%
Given the unknown ground-state solution density $p=|\psi_0|^2/\Vert\psi_0\Vert$ (also called {\it the target} of the Metropolis algorithm), which is defined on the sample space $\Omega$, and computable up to a multiplying constant (due to the Rayleigh--Ritz principle $p \;\propto \;\tilde{p}$).
%
The Metropolis--Hastings algorithm then proposes a generic way to construct a Markov chain on $\Omega$ that is {\it ergodic} and {\it stationary} with respect to $p$ and therefore converges by the ergodic theorem in distribution to $p$ \cite{norris1998markov,durrett2016essentials}.
%
Due to its simplicity and versatility, the Metropolis--Hastings algorithm is the most used Markov-Chain Monte--Carlos method.
%
This makes it the first solution to consider for intractable situations after homogeneously distributed sampling algorithms (cf.~\cite{robert2010introducing}). 
%
The main motivation for using Markov chains is that they provide {\it shortcuts} in cases where generic sampling requires too much effort from the experimenter.
%
Rather than aiming at the big picture, like homogeneously distributed sampling algorithm, Markov chains construct a progressive picture of the target distribution, proceeding by local exploration of the state space $\Omega$ until all the regions of interest have been uncovered. \\
We start this section by briefly introducing the necessary concept of Markov-chains:\\

%
Markov chains are one of the most important classes of stochastic processes, as they appear in various time-evolution models.
%
In the following, we restrict the introduction to discrete time-homogeneous Markov chains on a finite dimensional sample set. 
%
A sequence of $\Omega'$-valued random variable $(X_n)_{n\in\mathbb{N}}$ is said to fulfill the {\it Markov property} if for all $k\in\mathbb{N}$ and all $\omega_1,\omega_2,...,\omega_{k+1}\in \Omega'$ the following holds:
\begin{align*}
\mathbb{P}(X_{k+1}=\omega_{k+1}|X_{k}=\omega_{k},X_{k-1}=\omega_{k-1},...,X_{1}=\omega_{1})
=
\mathbb{P}(X_{k+1}=\omega_{k+1}|X_{k}=\omega_{k})~,
\end{align*}
where $\mathbb{P}(\cdot|\cdot)$ describes the {\it conditional probability}.
%
Hence, if a stochastic process fulfills the Markov property, the $k+1$-step is only depending on the $k$ step, i.e., the Markov chain has no memory\footnote{This is the major and most important difference between Markov chains and Martingales -- another class of important stochastic processes.}.
%
As we only consider Markov chains on a finite dimensional sample set, we use the class of stochastic matrices $\mathcal{S}$ to describe a Markov process, i.e., 
\begin{align*}
\mathcal{S} = \bigg\lbrace S\in \mathbb{R}^{m\times m} | S_{i,j}\in[0,1]\,\forall i,j\in\{1,...,m\}, \sum_{i=j}^mS_{i,j}=1\,\forall i\in\{1,...,m\} \bigg\rbrace~.
\end{align*}
We then define a Markov chain as follows:\\

\textit{
Let $S\in\mathcal{S}$ be a stochastic matrix. 
%
A sequence of $\Omega'$-valued random variable $(X_n)_{n\in\mathbb{N}}$ is called a time-homogeneous Markov chain with transition matrix $S$ is for all $k\in\mathbb{N}$ and all $\omega_1,\omega_2,...,\omega_{k+1}\in \Omega'$ with $\mathbb{P}(X_{k}=\omega_{k},X_{k-1}=\omega_{k-1},...,X_{1}=\omega_{1})>0$ the following holds:
\begin{align*}
\mathbb{P}(X_{k+1}=\omega_{k+1}|X_{k}=\omega_{k},X_{k-1}=\omega_{k-1},...,X_{1}=\omega_{1})
=S_{\omega_k,\omega_k+1}~.
\end{align*}
The matrix entries $S_{i,j}$ are called transition probabilities and the initial distribution $\mu$ is defined by $\mu(\omega)=\mathbb{P}(X_1=\omega)$ for $\omega\in\Omega'$.\\
}

An important feature of Markov chain is a {\it stationary distribution}, i.e., a distribution $\nu$ that stays invariant under the Markov chain and therewith fulfilling the matrix equation $\nu S = \nu$. 
%
The existence and uniqueness of such stationary distributions depends strongly on the Markov chain. 
%
The for the Metropolis algorithm central theorem, is the {\it ergodic theorem for time-homogeneous Markov chains on a finite dimensional sample space} \cite{norris1998markov,durrett2016essentials}. 
%
It states that for an {\it aperiodic} and {\it irreducible} Markov chain with transition matrix $S$, $\nu S^n\overset{\mathbb{P}}{\longrightarrow}\mu$ for $n\to \infty$ and any initial distribution $\nu$, with $\mu$ being the stationary distribution.
%
We again used the standard notation from probability theory, where $\nu S^n\overset{\mathbb{P}}{\longrightarrow}\mu$  denotes the convergence in probability, i.e., for all $\varepsilon > 0 $ we have 
\begin{align*}
\lim_{n\to \infty}\mathbb{P}(|\nu S^n - \mu|\geq\varepsilon)=0~.
\end{align*} 
%
Note that demanding the Markov chain with transition matrix $S$ to be {\it aperiodic} and {\it irreducible} is the same as demanding the existence of $n\in\mathbb{N}$ such that $S^n_{i,j}>0$ for all $i,j$, i.e., the Markov chain is ergodic.
%
The aim is now to construct an ergodic Markov chain that converges to the ground-state solution density $p$, we follow hereby the reasoning presented in \cite{robert1999metropolis}:

%
The Markov chain $(X_{n})_{n\in\mathbb{N}}$ returned by the Metropolis-Hastings method is indeed such that it converges to $p$~\cite{metropolis1953equation}. 
%
This means that the chain can be considered as a sample, albeit a dependent sample, and approximately distributed from $p$. 
%
Due to the Markovian nature of the simulation, the first values are highly dependent on the initial distribution and therewith from $X_1$.
%
Consequently, these are removed from the sample as {\it warm-up}, also called {\it burn-in}. 
%
While there are very few settings where the time when the chain reaches stationarity can be determined \cite{hobert2004mixture}, there is no need to look for such an instant since the empirical average
\begin{align*}
\frac{1}{N}\sum_{n=1}^NP(X_i;a)E_L(X_i;a)
\end{align*}
converges almost surely if the Markov chain is ergodic. 
%
Comparing this to \eqref{eq:StrongLawofBN} it implies that, in theory, simulating a Markov chain is intrinsically equivalent to the pairwise independent identically distributed simulation from the target.
%
Note, that the difference being in a loss of efficiency, i.e., it is necessary to simulate more terms to achieve a given variance for the above Monte Carlo estimator. 


The Metropolis-Hastings algorithm associated with the target density $p$ requires the choice of a conditional density $q$ also called {\it proposal} or {\it candidate kernel}.  
%
The transition $t\to t+1$ is then given by Algorithm \ref{Alg:Metropolis-Hasting}.
\begin{algorithm}
	\caption{Metropolis--Hasting}
	\label{Alg:Metropolis-Hasting}
	\begin{algorithmic}[1]
		\Procedure{Create Metropolis-Hasting Markov Chain}{}
		\State Given $X_t = x_t$
		\State Generate $Y_t\sim q(y | x_t)$
		\State Take 
		\begin{align*}
		X_{t+1}=\left\lbrace 
		\begin{aligned}
		Y_t, &\text{ with probability } \rho(x_t,Y_t),\\
		x_t, &\text{ with probability } 1- \rho(x_t,Y_t),
		\end{aligned}
		\right.
		\end{align*}
		where 
		\begin{align*}
		\rho(x,y) = \min\left\lbrace 1, \frac{\tilde{p}(y)q(x|y)}{\tilde{p}(x)q(y|x)}\right\rbrace.
		\end{align*}
		\EndProcedure
	\end{algorithmic}
\end{algorithm}


Then, as shown in \cite{metropolis1953equation}, this transition preserves the stationary density $p$ if the chain is irreducible, i.e., $q$ has a wide enough support to eventually reach any region of the state space $\Omega'$ with positive mass under $p$. 
%
As mentioned before, a sufficient condition is that $q$ is positive everywhere. 
%
The very nature of accept-reject step introduced by Metropolis et al.~\cite{metropolis1953equation} is therefore sufficient to turn a simulation from an almost arbitrary proposal density $q$ into a generation that preserves $p$ as the stationary distribution. 
%
This appears somewhat surprising but works indeed, as shown in theoretical description above.
%
In practice, the performances of the algorithm are highly dependent on the choice of the transition $q$, since some choices see the chain unable to converge in a manageable time.
%
In this work we use $X_t$ perturbed by a normal distribution, i.e., $Y_t\sim X_t+\varepsilon_t$ with $\varepsilon_t\sim \mathcal{N}(0,1)$.


\subsubsection{Importance Sampling}
%
%
Despite the Metropolis--Hasting sampling's simplicity, we replace this brute force algorithm with a walk in coordinate space biased by the trial wave function. 
%
This {\it importance sampling} is based on a stochastic differential equation, namely the {\it Langevin equation}, i.e.,
\begin{align*}
\frac{d^{2}x}{dt^{2}}=-\lambda \frac{dx}{dt}+\eta\left( t\right),
\end{align*}
with the position ${x}$ of a particle of mass one. 
%
The noise term $\eta \left(t\right)$ follows a Gaussian probability distribution, where the correlation function depends on the physical problem. 
%
For this work, however, we are not interested in a solution of a Langevin equation for a particular realization of the fluctuating force.
%
Rather, we are interested in correlation functions of the slow variables after averaging over the fluctuating force. 
%
As shown in \cite{risken1989fokker,coifman2008diffusion,ichimaru1973basic}, such correlation functions can be described by the {\it Fokker--Planck equation}, a deterministic differential equation. 
%
Unlike Langevin equations, the Fokker--Planck equation describes a time dependent probability density of a random variable and not the random variable itself.
%
We shall see that the important sampling is not as far from the previously described  Metropolis--Hasting sampling, which was derived from the theory of discrete time-homogeneous Markov chains on a finite dimensional sample set.

%
Subsequently, we present a quick and dirty derivation of the Fokker--Planck equation, by shortly dropping the mathematical rigor of this work. 
%
We now consider time-continuous Markov chains, i.e.,

\textit{
The stochastic process $(X_t)_{t\geq 0 }$ is called a time continuous Markov chain, if for all $0\leq s_0<s_1<...<s_n<s$ and all possible events $\omega_0,\omega_1,...\omega_n,\omega_i,\omega_j\in\Omega'$ the following holds
\begin{align*}
\mathbb{P}(X_{t+s}=\omega_j|X_{s}=\omega_i,X_{s_n}=\omega_n,..., X_{s_0}=\omega_0)
=
\mathbb{P}(X_{t}=\omega_j|X_{0}=\omega_i)
\end{align*}
} 
The Markov property and the definition of the conditional probability we derive straightforwardly the Chapman-Kolmogorow equality. 
%
From the Markov property we obtain
\begin{align*}
\mathbb{P}&(X_{t_3}=\omega_{3},X_{t_2}=\omega_{2},X_{t_1}=\omega_{1})\\
&=
\mathbb{P}(X_{t_1}=\omega_{1})\mathbb{P}(X_{t_2}=\omega_{2}|X_{t_1}=\omega_{1})\mathbb{P}(X_{t_3}=\omega_{3}|X_{t_2}=\omega_{2})
\end{align*}
which is equivalent to
\begin{align*}
\mathbb{P}(X_{t_3}=\omega_{3},X_{t_1}=\omega_{1})
=
\mathbb{P}(X_{t_1}=\omega_{1})\int_{\Omega'}\mathbb{P}(X_{t_2}=\omega_{2}|X_{t_1}=\omega_{1})\mathbb{P}(X_{t_3}=\omega_{3}|X_{t_2}=\omega_{2})d\omega_{2}~.
\end{align*}
Division by $\mathbb{P}(X_{t_1}=\omega_{1})$ yields the {\it Chapman-Kolmogorow} equality
\begin{align*}
\label{eq:Chapman-Kolmogorow}
\mathbb{P}(X_{t_3}=\omega_{3}|X_{t_1}=\omega_{1})
=\int_{\Omega'}\mathbb{P}(X_{t_2}=\omega_{2}|X_{t_1}=\omega_{1})\mathbb{P}(X_{t_3}=\omega_{3}|X_{t_2}=\omega_{2})d\omega_{2}
\end{align*}
and considering the times $t'\leq t'+\tau\leq t$ this reads
\begin{align}
\label{eq:Chapman-KolmogorowApl}
\mathbb{P}(X_{t}=\omega|X_{t'}=\omega')
=\int_{\Omega'}\mathbb{P}(X_{t}=\omega|X_{t'+\tau}=\omega'')\mathbb{P}(X_{t'+\tau}=\omega''|X_{t'}=\omega' )d\omega''~.
\end{align}
By construction of the delta distribution, we further have
\begin{align}
\label{eq:Integrant1}
\mathbb{P}(X_{t'+\tau}=\omega''|X_{t'}=\omega')
=
\int_{\Omega'}\mathbb{P}(X_{t'+\tau}=y|X_{t'}=\omega')\delta(y-\omega'')dy~.
\end{align}
Inserting the Taylor expansion of the delta distribution, i.e.,
\begin{align*}
\delta(y-\omega'') = \sum_{n=0}^{\infty}\frac{(y-\omega')^n}{n!}\left( \frac{\partial}{\partial \omega'} \right)^n\delta(\omega'-\omega'')
\end{align*}
into Eq.~\eqref{eq:Integrant1}, we obtain
\begin{align*}
\mathbb{P}(X_{t'+\tau}=\omega''|X_{t'}=\omega')
=
\Bigg(
1+\sum_{n=0}^{\infty}\frac{1}{n!}
\underbrace{\int_{\Omega'}(y-x')^n\mathbb{P}(X_{t'+\tau}=y|X_t'=\omega')dy}_{=M_n(\omega',t',\tau)}\left( \frac{\partial}{\partial x'} \right)^n
\Bigg)\delta(\omega'-\omega'')~.
\end{align*}
Inserting this into Eq.~\eqref{eq:Chapman-KolmogorowApl} yields
\begin{align*}
\label{eq:Chapman-KolmogorowApl2}
\mathbb{P}(X_{t}=\omega|X_{t'}=\omega')
&=
%\int_{\Omega'}\mathbb{P}(X_{t}=\omega|X_{t'+\tau}=\omega'')
%\left(
%1+\sum_{n=0}^{\infty}\frac{1}{n!}
%M_n(\omega',t',\tau)\left( \frac{\partial}{\partial \omega'} \right)^n
%\right)\delta(\omega'-\omega'')
%d\omega''\\
%&=
\mathbb{P}(X_{t}=\omega|X_{t'+\tau}=\omega')
+\sum_{n=0}^{\infty}\frac{1}{n!}M_n(\omega',t',\tau)\left( \frac{\partial}{\partial \omega'} \right)^n
\mathbb{P}(X_{t}=\omega|X_{t'+\tau}=\omega')~.
\end{align*}
As mentioned above, the Fokker-Planck equation is a deterministic differential equation describing the probability density of a random variable. To meet that end, we take a closer look a differential quotient
\begin{align*}
\frac{\partial \mathbb{P}(X_{t}=\omega|X_{t'}=\omega')}{\partial t'}
=
-\lim_{\tau\to 0} \frac{\mathbb{P}(X_{t}=\omega|X_{t'}=\omega')-\mathbb{P}(X_{t}=\omega|X_{t'+\tau}=\omega')}{\tau}~,
\end{align*}
together with Eq.~\eqref{eq:Chapman-KolmogorowApl2} this can be written as
\begin{align*}
\frac{\partial \mathbb{P}(X_{t}=\omega|X_{t'}=\omega')}{\partial t'}
=
-\lim_{\tau\to 0} \frac{1}{\tau}\sum_{n=0}^{\infty}\frac{1}{n!}M_n(\omega',t',\tau)\left( \frac{\partial}{\partial \omega'} \right)^n
\mathbb{P}(X_{t}=\omega|X_{t'+\tau}=\omega')~.
\end{align*}
Using the Taylor expansion of $M_n(\omega',t',\tau)$, i.e.,
\begin{align*}
\frac{M_n(\omega',t',\tau)}{n!} = 0+D^{(n)}(\omega',t')\tau+\mathcal{O}(\tau^2),\quad\text{with } D^{(n)}(\omega',t') = \lim_{\tau'\to 0}\mathbb{E}((X_{t'+\tau'}-X_{t'})^n)\big|_{X_{t'}=\omega'}
\end{align*}
yields the differential equation
\begin{align}
\label{eq:Fokker-Planck-Prob}
\frac{\partial \mathbb{P}(X_{t}=\omega|X_{t'}=\omega')}{\partial t'}
=
-\mathcal{L}_{KM}^{\dagger}(\omega',t')\mathbb{P}(X_{t}=\omega|X_{t'}=\omega')
\end{align}
with the {\it Kramers--Moyal operator}
\begin{align*}
\mathcal{L}_{KM}(\omega',t')&=\sum_{n=0}^{\infty}\left(- \frac{\partial}{\partial \omega'}\right)^nD^{(n)}(\omega',t')~,\\
\mathcal{L}_{KM}^{\dagger}(\omega',t'&)=\sum_{n=0}^{\infty}D^{(n)}(\omega',t')\left( \frac{\partial}{\partial \omega'}\right)^n~.
\end{align*} 
Similar to Eq.~\eqref{eq:Fokker-Planck-Prob} with find the analog deterministic differential equation
\begin{align}
\label{eq:Fokker-Planck}
\frac{\partial P(\omega,t)}{\partial t}
=
\mathcal{L}_{KM}(\omega,t)P(\omega,t)
\end{align}
describing the time evolution of the probability density $P(\omega,t)$.
%
The mayor question arising at this point is under which circumstances this expansion terminates.
%
The answer is given by Pawulas theorem\cite{risken1989fokker}:\\

\textit{
For positive transition probabilities $\mathbb{P}(\omega, t| \omega', t')$ the expansion in Eq.~\eqref{eq:Fokker-Planck} terminates after one or two terms. If it does not terminate after the second term it never terminates.\\
}

If the expansion in Eq.~\eqref{eq:Fokker-Planck} terminates after the second term, the resulting differential equation is called a Fokker-Planck equation:
\begin{align*}
\frac{\partial P(\omega,t)}{\partial t}
=
-\frac{\partial}{\partial \omega}D^{(1)}(\omega,t)P(\omega,t)
+
\frac{\partial^2}{\partial \omega^2}D^{(2)}(\omega,t)P(\omega,t)
=
\mathcal{L}_{FP} P(\omega,t)~,
\end{align*}
with the Fokker-Planck operator
\begin{align*}
\mathcal{L}_{FP}
=
-\frac{\partial}{\partial \omega}D^{(1)}(\omega,t)
+
\frac{\partial^2}{\partial (\omega)^2}D^{(2)}(\omega,t)~.
\end{align*}
The term $D^{(1)}$ is called {\it drift coefficient} and is responsible for the time-evolution of the random variables mean value. 
%
The term $D^{(2)}$ is called {\it diffusion coefficient} and is responsible for the time-evolution of the random variables standard deviation.
%
In this work we consider a constant diffusion coefficient, in atomic unties, $D^{(2)}=1/2$. 
%
Consequently, the convergence to a stationary probability density, i.e., ${\partial P(\omega,t)}/{\partial t}=0$, then corresponds to the solution of
\begin{align*}
\frac{\partial^2}{\partial (\omega)^2}P(\omega,t)
=
D^{(1)}(\omega,t)\frac{\partial}{\partial \omega}P(\omega,t)
+
P(\omega,t)\frac{\partial}{\partial \omega}D^{(1)}(\omega,t)~.
\end{align*}
We assume the drift coefficient to be of the form $D^{(1)}(\omega,t) = g(\omega,t)\partial P(\omega,t)/\partial \omega$. 
%
Together with {\it Random--Nikodym theorem} this yields
\begin{align*}
\frac{\partial^2P(\omega,t)}{\partial (\omega)^2}
=
g(\omega,t)\left(\frac{\partial P(\omega,t)}{\partial \omega}\right)^2
+
P(\omega,t)g(\omega,t) \frac{\partial^2 P(\omega,t)}{\partial \omega^2}
+
P(\omega,t)\frac{\partial g(\omega,t)}{\partial P(\omega,t)}\left(\frac{\partial P(\omega,t)}{\partial \omega}\right)^2~.
\end{align*}
For $g(\omega,t)=1/P(\omega,t)$ this equality is fulfilled.
%
Indeed,
\begin{align*}
\frac{\partial^2P(\omega,t)}{\partial (\omega)^2}
&=
\frac{1}{P(\omega,t)}\left(\frac{\partial P(\omega,t)}{\partial \omega}\right)^2
+
\frac{\partial^2 P(\omega,t)}{\partial \omega^2}
+
P(\omega,t)\left(-\frac{1}{P^2(\omega,t)}
\right)\left(\frac{\partial P(\omega,t)}{\partial \omega}\right)^2~.
\end{align*}
As in this work $P = |\psi_T|^2$ this yields
\begin{align*}
D^{(1)}(\omega,t)
=
\frac{1}{P}\frac{\partial P}{\partial \omega}
=
2\frac{1}{\psi_T}\nabla\psi_T = F~,
\end{align*}
which is also known as {\it quantum force}.
%
As the drift coefficient describes the movement of the mean value, it is this term that forces the taken samples, also called walkers, into regions of the configuration space where the trial wave function $\psi_t$ is large.
%
This increases the simulation's efficiency in contrast to the here considered Metropolis--Hastings sampling where the samples are normally distributed, i.e, they have the same probability of moving in every direction.
%
Using the Green's functions theory, we obtain a solution of above described Fokker-Planck equation, implying the following description of transition probabilities 
\begin{align*}
G(x,y,\Delta t)
=
\frac{1}{(2\pi \Delta t)}\exp\left( -\frac{(y-x-\frac{\Delta t F(x)}{2})}{2\Delta t}\right)~,
\end{align*}
where we used $D^{(2)}=1/2$.

%
Using the Langevin equation we can describe the random variable of the transition probability using an {\it explicit Euler procedure} with time step size $\Delta t$, i.e.,
\begin{align*}
Y_t = X_t + D^{(2)}F(X_t) \Delta t+ \xi \sqrt{\Delta t}~.
\end{align*}
Using this random variable and the transition probability described by the Fokker--Planck's Greens function in the Metropolis--Hastings algorithm we obtain the importance sampling, see Alg.~\ref{Alg:ImportanceSampling}.

\begin{algorithm}
	\caption{Importance Sampling}
	\label{Alg:ImportanceSampling}
	\begin{algorithmic}[1]
		\Procedure{Create Importance Sampling Markov Chain}{}
		\State Given $X_t = x_t$
		\State Generate $Y_t\sim X_t + D^{(2)}F(X_t) \Delta t+ \xi \sqrt{\Delta t}$
		\State Take 
		\begin{align*}
		X_{t+1}=\left\lbrace 
		\begin{aligned}
		Y_t, &\text{ with probability } \rho(x_t,Y_t),\\
		x_t, &\text{ with probability } 1- \rho(x_t,Y_t),
		\end{aligned}
		\right.
		\end{align*}
		where 
		\begin{align*}
		\rho(x,y) = \min\left\lbrace 1, \frac{G(x,y,\Delta t)|\psi_T(y)|^2}{G(y,x,\Delta t)|\psi_T(x)|^2}\right\rbrace.
		\end{align*}
		\EndProcedure
	\end{algorithmic}
\end{algorithm}


  
\subsection{Statistical Analysis}
%
%
%
In this section, we describe the statistical tools that will be used for a proper evaluation of our data's statistical errors.
%
The computational results are obtained by using Monte Carlo simulations.
%
These simulations can be treated as computational experiments and its results can therefore be analyzed with the same statistical tools used for laboratory experiments.
%
We hereby focus on two {\it resampling method}, i.e. methods that estimate the precision of sample statistics (medians, variances, percentiles), namely:
\begin{itemize}
%\item The \textit{jackknife technique} also called \textit{jackknifing}, where the estimation is based on using subsets of available data.
\item The \textit{bootstrap technique} also called \textit{bootstrapping}, where the estimation is based on drawing randomly with replacement from a set of data points.
\item The \textit{blocking method} also just \textit{blocking}, where the samples are divided in sub-samples of certain size, allowing to use estimators for uncorrelated samples. 
\end{itemize}
%
The estimators used in this work are a {\it mean estimator} defined by 
\begin{align*}
\hat \Theta(X)= \hat \Theta(X_1,...,X_n) = \frac{1}{n}\sum_{i=1}^nX_i=\overline{X}
\end{align*}
and a {\it variance estimator} defined by 
\begin{align*}
\hat \varphi(X)=\hat \varphi(X_1,...,X_n) = \frac{1}{n-1}\sum_{i=1}^n(X_i-\overline{X})^2=S^2X~,
\end{align*}
where $X= (X_1,...,X_n)$ describes a set of samples.
\subsubsection{Bootstrapping}
%
%
In the wider sense of statistical analysis, any test that relies on random sampling with replacement is called bootstrapping.
%
This technique allows the estimation of the sampling distribution and provides an error analysis assigning measures of accuracy defined in terms of bias, variance, confidence intervals, prediction error.  
%
The basic idea of bootstrapping is treating inference of the true probability distribution $J$, given the original data, as being analogous to inference of the empirical distribution of $\hat J$, given the resampled data.
%
The accuracy of inferences regarding $\hat J$ using the resampled data is assessable because $\hat J$ is known. 
%
Assuming that $\hat J$ is a {\it reasonable approximation} to the unknown distribution $J$, then the quality of inference on $J$ can in turn be inferred.
%
In a more informal way bootstrapping can be described as follows:

%
Assume we are interested in the mean value of $X_1,...,X_K$ independently and identically $J$-distributed with $K$ being very large. 
%
If $K$ becomes too large, we have to restrict the evaluation to a subset of size $n$.
%
Without loss of generality we denote this subset by $X_1,...,X_n$ with $n\ll K$.
%
From this sample the mean estimator yields a single estimate $\overline{X}=\hat \Theta(X_1,...,X_n)$. 
%
In order to reason about $ \Theta(X_1,...,X_K)$, we need a sense of the variability of the mean $\overline{X}$. 
%
Bootstrapping now treats the sample $X_1,...,X_n$ in the same way as $X_1,...,X_K$.
%
A straightforward bootstrap approach therefore involves sampling from $X_1,...,X_n$ to form a new sample (called a {\it resample} or {\it bootstrap sample}) of the same size.
%
Under the assumption that $n$ is sufficiently large, there is practically zero probability that the sample will be identical to the original real sample.
%
This process is repeated numerous times, and for each of these bootstrap samples the mean is computed, the so-called {\it bootstrap estimates}. 
%
This yields a histogram of bootstrap means providing an estimate of the unknown distribution's mean.
%
How much the mean varies can then be deduced from this histogram and used to measure the quality of the mean computed from the original sample. 

%
The above described method is also called {\it non-parametric Bootstrap}, and is used when the distribution $J$ is unknown.
%
We summarize this algorithm in the following pseudo-code Alg.~\eqref{Alg:Non-parametricBootstrap}:
\begin{algorithm}
	\caption{Non-parametric Bootstrap}
	\label{Alg:Non-parametricBootstrap}
	\begin{algorithmic}[1]
		\Procedure{Creat Bootstrap Sample Histogram}{}
		\State Draw histogram of $X(P^*(X))$
		\Procedure{Bootstrap Sample}{}
		\State Draw from $P^*(X)$, $n$ random numbers $\{X_i\}=X^*$
		\State Compute $\hat \Theta (X^*)=t(X^*)$
		\State write $t$ to memory 
		\EndProcedure
		\State Use Bootstrap Samples to obtain the final histogram $P^*(\hat \Theta)$
		\EndProcedure
	\end{algorithmic}
\end{algorithm}

%
In the case the histogram $P(X)$ is known, we resample from this histogram and do the Bootstrap sample steps from Alg.~\eqref{Alg:Non-parametricBootstrap}. 
%
This is then known as {\it parametric Bootstrap}.








\subsubsection{Blocking}
%
%
The Blocking method is used for correlated data samples, where we can no longer use the estimators for uncorrelated sample sets.
%
In blocking methods, the sample set $X$ is grouped into sets of blocks $\{X^{(i)}\}$, where $X^{(i)}$ describes a blocked sample set.
%
The idea is now to use a block size large enough such that the elements of the different blocks are independent, which allows us to apply the estimators for uncorrelated sample sets to the blocked sample sets.  
%
Note that various possibilities exist to block the original sample set.
%
The blocking procedure used in this work is introduced in the sequel. 

%
We start this section by describing the approach of blocking methods in a more descriptive way.
%
Consider experimental data from a Monte Carlo simulation of step size $\Delta t$. 
%
In case of uncorrelated samples the mean's standard deviation is given by
\begin{align}
\label{eq:StandardDeviation}
\sigma 
=
\sqrt{
\hat \varphi(X)
}~.
\end{align}
The Monte Carlo simulation however, will most likely produce a correlated sample set.
%
In this case the standard deviation needs to be corrected as follows  
\begin{align*}
\sigma
=
\sqrt{
\frac{1+2\tau/\Delta t}{n-1}\Big(\overline{X^2}-\overline{X}^2\Big)
}~,
\end{align*}
where $\tau$ is the so called {\it correlation time}, i.e., the time between a sample and the next uncorrelated sample.
%
In case $\Delta t\gg\tau$ the Monte Carlo samples will be uncorrelated and Eq.~\eqref{eq:StandardDeviation} can be used to compute the standard deviation.
%
As mentioned before, it is most likely that $\Delta t<\tau$, in which case Eq.~\eqref{eq:StandardDeviation} is not valid anymore. 
%
Furthermore, we are facing the difficulty of not knowing the correlation time $\tau$.
%
However, with blocking we are still able to determine a valid standard deviation of the mean $\overline{X}$.
%
Using the uncorrelated expression Eq.~\eqref{eq:StandardDeviation}, we compute the mean of each block $\overline{X^{(i)}}$ with $i=1,...,n_{b}$ where $n_b$ is the number of blocks, and calculate then the total mean and variance.
%
The crucial part for this method is the block size, i.e., it must be so large that sample $j$ of block $i$ is not correlated with sample $j$ of block $i+1$.
%
An optimal choice would therefore be the unknown correlation time. 
%
A quick and dirty solution to this problem is a manual fix of the block size:

A graphical representation of the standard deviation as a function of the block size will show a plateau region, i.e., a connected set of block sizes for which the standard deviation is constant. 
%
As soon as the standard deviation stops increasing, we know that the blocks are uncorrelated. 
%
This number can then be manually put into the blocking algorithm. 

% 
An alternative to this brute force fix of the blocking method, is the {\it automatic blocking}.
%
We here proceed as follows:

%
For a given set of samples $(X_1,...,X_n)$ with $n=2^d$ we create the block set
\begin{align*}
X^{(1)}&=\big(\frac{1}{2}(X_1+X_2),...,\frac{1}{2}(X_{n-1}+X_n)\big) = \big(X_1^{(1)},...,X_{n_1}^{(1)}\big)~,\\
&~\vdots\\
X^{(d)}&=\big(\frac{1}{2}(X_1^{(d-1)}+X_2^{(d-1)}),...,\frac{1}{2}(X_{n_{d-1}-1}^{(d-1)}+X_{n_{d-1}}^{(d-1)})\big) = \big(X_1^{(d)},...,X_{n_d}^{(d)}\big)~.
\end{align*} 
From these block we can compute various quantities like the mean and the variance, and many which will be used to derive an automatized blocking method. 
%
Before going into further detail of these quantities, however, we introduce some more statistical concepts.
%
We define the so-called auto-variance $f_d$ for $m$ experiments of $n$ samples by
\begin{align*}
f_d = \frac{1}{n m}\sum_{\alpha = 1}^{m}\sum_{k=1}^{n-d}(x_{\alpha,k}-\langle x_m\rangle)(x_{\alpha,k+d}-\langle x_m\rangle)~,
\end{align*} 
where $\langle x_m\rangle$ denotes the means over all samples, i.e.,
\begin{align*}
\langle x_m\rangle := \frac{1}{nm}\sum_{\alpha = 1}^{m}\sum_{k=1}^{n}x_{\alpha,k}~.
\end{align*}
The total variance
\begin{align*}
\sigma_m
=
\frac{1}{mn^2}\sum_{\alpha = }^{m}\sum_{k,l = 1}^{n}(x_{\alpha,k}-\langle x_m\rangle)(x_{\alpha,l}-\langle x_m\rangle)
\end{align*}
can then be written as
\begin{align*}
\sigma_m
=
\frac{\sigma^2}{n}
+
\frac{2}{n}\sum_{d = 1}^{n-1}f_d~,
\end{align*}
where 
\begin{align*}
\sigma^2
=
\frac{1}{mn}\sum_{\alpha=1}^{m}\sum_{k=1}^{n}(x_{\alpha,k}-\langle x_m\rangle)^2~.
\end{align*}
For the sake of completeness note that the expression 
\begin{align*}
\mathcal{E} :=\frac{2}{n}\sum_{d = 1}^{n-1}f_d
\end{align*}
describes the covariance.
%
For each blocked sample set $X^{(i)}$ we can then compute the total variance
\begin{align*}
\mathbb{V}(\overline{X^{(i)}})
=
\frac{\mathbb{V}(X^{(i)})}{n_i}+\mathcal{E}_i~.
\end{align*}
We then state the following proposition [CITE MARIUS...]\\

{\it If $X_1,...,X_n$ is stationary, i.e., it exists a real number $c$ such that $\langle X_i\rangle=c$ for all $i$, and $\mathbb{V}(X_i)<\infty$ for one $i$, then $\mathcal{E}_i-\mathcal{E}_{i+1}= \mathrm{cov}(X^{(i)}_{j+1},X^{(i)}_j)/n_i=:\gamma^i(1)/n_i$.\\}

Furthermore, it is straightforward that $\mathcal{E}_i$ is a monotone function in $i$ is we assume that $\gamma^k(1)>0$ for all $1\leq k\leq d_1$.
%
Hence, if $X^{(i)}$ has independent elements, then $\mathcal{E}_k=0$ and $\gamma^k(1)=0$ for all $k\geq i$. 
%
The inverse of this statement follows immediate as the covariance of independent samples is equal to zero.
%
This yields the condition used to automatize the blocking method, namely, we stop blocking if $\gamma^k(1)=0$.  
%
Before presenting the pseudo-code for the automatic blocking method, we give the following theorem [CITE MARIUS...] on which the procedure is based on:

{\it 
Let $X_1,...,X_n$ with $n=2^d$ be stationary, with $\mathbb{V}(X_i)<\infty$ for one $i$ and $\gamma(h)\to \infty$.
%
Then the following implication holds:\\
If $\gamma^k(1)=0$ then
\begin{align*}
M_j := \sum_{k=1}^{d-1}\frac{n_k\big((n_k-1)(S^{(k)})^2/nk+\gamma^k(1)\big)2}{(S^{(k)})^4}
\end{align*}
is chi-squared distributed ($M_j\sim\chi^2$).
}
We finalize this section by presenting a pseudo-code for the automatic blocking method, see Alg.~\eqref{Alg:AutomaticBlocking}.

\begin{algorithm}
	\caption{Automatic Blocking}
	\label{Alg:AutomaticBlocking}
	\begin{algorithmic}[1]
		\Procedure{Estimate $\mathbb{V}(\overline{X})$}{}
		\State Set $i=1$
		\State Compute $\big(S^{(i)}\big)^2, \, \hat\gamma^i(1)$
		\State Transform $Q^{(i)}\to Q^{(i+1)}$
		\If{$|Q^{(i)}|\leq 2$} 
		\State Compute $M_j$ using $\hat{\gamma}^j(1)$ and $\big(S^{(j)}\big)^2$ 
		\State Find the first $k$ such that $M_k\leq q_k$
		\State Return $\big(S^{(k)}\big)^2/n_k$
		\Else
		\State Go back to  2
		\EndIf
		\EndProcedure
	\end{algorithmic}
\end{algorithm}
































\subsection{Numerical optimisation}
Choosing the ideal trial wave function is an integral part of computing the ground-state energy. The way the ideal trial wave function is found is by computing
\begin{equation}
    \text{arg} \min_{\alpha} E_L[\psi(\cdot, \alpha)] = \text{arg} \min_{\alpha} \tilde{E}_L(\alpha), \label{eq:optimisation.problem}
\end{equation}
where $\alpha \in \mathbb{R}^k$ is the variational parameter(s) of our trial wavefunction. Thus, a VMC program should also solve a optimisation problem, which will be the focus of the following section.

One way of solving the problem in \cref{eq:optimisation.problem} is by computing the gradient, $\nabla_\alpha E_L(\alpha)$ and finding its roots. This is, unfortunately, an NP-hard problem in general [CITE HERE] and numerical optimisation methdos is therefore used instead.

The main class of optimisation methods we will consider is decent-direction based algorithms [SOME CITE HERE]. A descent direction of $\tilde{E}_L: \mathbb{R}^k \to \mathbb{R}$ in $\alpha_i \in \mathbb{R}^k$ is a vector $\bm{p}_i \in \mathbb{R}^k$ such that
\begin{equation}
    \tilde{E}_L(\alpha_i + \xi_i \bm{p}_i) < \tilde{E}_L(\alpha_i),
\end{equation}
for all $\xi_i < \epsilon_i$, with $\epsilon_i$ being some (often unknown) real number. To put it informally, a descent direction is a direction where the function decreases. How these directions are found will be discussed later, first we introduce descent direction based algorithms.

\begin{algorithm}
	\caption{Descen-direction based optimisation}
	\label{Alg:descentOptimisation}
	\begin{algorithmic}[1]
        \State Start with initial $\alpha_0$
        \Procedure{Minimise $\tilde{E}_L$}{}
        \State $i \gets 0$.
        \While{$\alpha$ not converged}
        \State Find a descent direction, $\bm{p}_i$
        \State Find a $\xi_i$ that gives a sufficent decrease.
        \State $\alpha_{i+1} \gets \alpha_i + \xi_i \bm{p}_i$.
        \State $i \gets i + 1$
        \EndWhile
		\EndProcedure
	\end{algorithmic}
\end{algorithm}

Thus, descent-direction based optimisation algorithms work by updating $\alpha_i$ such that the target-function, $\tilde{E}_L$, decreases every iteration. There are two parts of the above algorithm that needs to be specified, the first is how the step-size, $\xi_i$ is found and the second is how the descent direction is found. 

Ideally, one wants to find the optimal step-size, however, that entails solving a optimisation problem itself, which can be computationally inefficient. Solving this optimisation problem is often reffered to as an \emph{exact line search} [CITE NOCEDAL]. An alternative to this is to test different step-sizes until some heuristic is fulfilled instead. One example of such a heuristic is the Wolfe conditions, which states that the a sufficient step size, $\xi_i$ is a step size that satisfies
\begin{equation}
    \tilde{E}_L(\alpha_i + \xi_i \bm{p}_i) \leq \tilde{E}_L(\alpha_i) + c_1\xi_i \nabla \tilde{E}_L(\alpha_i)^T\bm{p}_i,
\end{equation}
and
\begin{equation}
    |\nabla \tilde{E}_L(alpha_i + \xi_i \bm{p}_i)^T\bm{p}_i| < c_2 |\nabla \tilde{E}_L(\alpha_i)^T \bm{p}_i |,
\end{equation}
for some $0 < c_i < c_2 < 1$ [CITE NOCEDAL]. This is called an \emph{inexact line search}. The first condition ensures that the decrease is sufficient, and the second condition ensures that the slope of the function has changed sufficiently. A result of the slope changing sufficiently is that the step-size is not chosen arbitrarily small, which is a possibility if this condition is left out.

Now, we focus on computing the descent direction. The first algorithm we discuss here is the gradient descent, or steepest descent algorithm. In this case, the descent-direction is chosen to be the direction where the function decreases most rapidly (locally). Incidentally, this is equivalent to setting $\bm{p}_i = -\nabla \tilde{E}_L$, which gives the algorithm its name, "gradient descent" [CITE NOCEDAL].

Another way of computing the descent-direction is performing a second degree Taylor approximation of $\tilde{E}_L$ and finding the direction pointing towards the minimum of this approximation. This is equivalent to finding a descent direction that satisfies
\begin{equation}
    (\nabla^2 \tilde{E}_L(\alpha_i))\bm{p}_i = -\nabla \tilde{E}_L,
\end{equation}
where $(\nabla^2 \tilde{E}_L(\alpha_i))$ is the Hessian matrix of $\tilde{E}_L$. This algorithm is called Newton's method. The main difference between Newton's method and gradient descent is that Newton's method takes the (local) curvature of the target function in consideration when finding a descent direction, whereas gradient descent does not [CITE NOCEDAL]. Considering this curvature information rapidly speeds up the convergence rate, from the linear convergence of gradient descent to quadratic convergence [CITE NOCEDAL].

There are two downsides Newton's method. The first downside is that it requires the computation of the Hessian matrix, which may be time-consuming. The second downside is that it involves solving a, often dense, linear set of equations, which has cubic complexity with respect to the dimensionality of $\alpha$. As a way to combat these shortcomings, several \emph{quasi Newton methods} exist,such as the "Broyden-Fletcher-Goldfarb-Shanno algorithm" (or BFGS) and the "Limited memory Broyden-Fletcher-Goldfarb-Shanno algorithm" (or L-BFGS). The idea of these algorithms is to estimate curvature information of the function instead of computing it explicitly and to (hopefully) do this in a matrix that is easy to invert [CITE NOCEDAL].

We want to conclude by noting that there is no difference between any of the descent-direction based algorithms in one dimension, as there is only a single descent direction in 1D. Thus, in 1D optimisation, the goal is equivalently to performing a single exact line search. This can, as noted earlier, be difficult in practice, especially when the function value and gradient is expensive to evaluate (which they are, as evaluating them entails a high dimensional integral). It can, however, bee shown that gradient descent converge to a local minimum if the step-size $\xi_i \leq \frac{2}{L}$, where $L$ is a Lipshitz constant of $E_L$, alternatively [cite]. If the step-size $\xi_i$ approaches zero as $i \to \infty$, this is guaranteed which yields convergence. We therefore choose such an optimisation scheme.

% Code/Implementations/test: 
%Here you should discuss how you implemented the algorithms, how you tested the algorithms,
%which other tests you have implemented, eventual  timings
%and possible benchmark calculations.  Clarity of codes are also included in the evaluation.
%Total number of possible points 20
\section{Implementation}
With this report follows a Python package for VMC calculations. The code follows the PEP-8 style guide and is documented using docstrings. Furthermore, Jupyter notebooks that demonstrate how to use the package is supplied. The following sections will describe how the code is structured and certain features used to optimise its runtime. Finally, we discuss some future steps that can be done to significantly speed up the computations.

\subsection{Class structure}
The package is structured using a hierarchy of classes, of which, the \texttt{Particle} class is at the lowest layer. A two-dimensional Numpy array of shape $n$-by-$d$, where $n$ is the number of particles and $d$ is the dimensionality of each particle's position vector, is used to store the positions of every particle. Furthermore, the distance between every particle is stored in an $n$-by-$n$ matrix and the difference between every particle is stored in an $n$-by-$n$-by-$d$ array. In addition to this, a boolean matrix is used to store whether any particles overlap, that is if the distance between two particles is less than their hard-core diameter. 

Furthermore, the particles class stores not only the current position of the particles, but also the previous position and all of their differences and distances, which reduces compute-time whenever a perturbation is rejected. The way this is done is by having two function, one named \texttt{perturb\_particle}, which updates the \texttt{\_old\_positions} and the \texttt{\_positions} matrices, if the perturbation is rejected, the \texttt{\_positions} matrix is set to be equal the \texttt{\_old\_positions} matrix. All differences and distances are lazily evaluated, and old versions of these are also stored so that they can be restored when a perturbation is rejected.

The next class is the \texttt{SingleParticleFunction} class, which has a \texttt{particles} attribute that specifies which \texttt{Particles} instance it should evaluate the the value of the single-particle function ($\phi(\bm{r_i})$), its relative gradient ($\frac{\nabla \phi(\bm{r}_i)}{\phi(\bm{r}_i)}$) and its relative laplacian ($\frac{\Delta \phi(\bm{r}_i)}{\phi(\bm{r}_i)}$ for.

The \texttt{WaveFunction}, as the name implies, computes the specifics of the wave-function of the system. It contains a \texttt{particles} attribute, that also specifies which particles to consider. The \texttt{WaveFunction} class also has a \texttt{single\_particle\_function} attribute which is an instance of the \texttt{SingleParticleFunction} that share the same \texttt{Particles} instance as the parent \texttt{WaveFunction}. The \texttt{WaveFunction} class allows computation of the current local energy, the quantum force and the value of the wave-function at the particle's current position.

Next, we introduce the \texttt{Sampler} classes, which allow for MCMC computations of the specified trial wave-function and hamiltonian, stored in the \texttt{wave\_function} attribute. The only difference between the \texttt{MetropolisSampler} and the \texttt{ImportanceSampler} are the \texttt{propose\_perturbation} and the \texttt{rejection\_criteria}, thus, all but these functions are implemented in the \texttt{Sampler} super-class from which the specific sampler classes inherits all information.

Finally, there is a \texttt{VMC} class, which works as a wrapper for the \texttt{Sampler} classes and allows for optimisation of the variational parameter. Furthermore, this class allows for easy parallel processing using joblib.

\subsection{Optimisation procedures}
Several steps were done to optimise the runtime of the code. Firstly, the \texttt{__setstate__} and \texttt{__getstate__} functions were created for the \texttt{WaveFunction} class to allow for easy serialisation (in Python known as pickling). This makes it possible to use the Multiprocessing module for parallel computation. The way parallel computation should be performed is that each process should spawn a separate \texttt{Sampler} instance with seed specified to be the process id.

Furthermore, the datastructure used to store the particles positions is a Numpy array. Thus, one particle's position is stored adjacently in memory, and all the particle's positions are stored as a single contiguous block of RAM. This allows for "single instruction, multiple data" (SIMD) to be used to optimise all operations done on the particles, which is used for all computations in this project.

There are mainly one optimisation step that can be performed to increase the runtime of the programme, namely to optimise the $\sum_{i=1}^n \sum_{j=1}^n -\frac{(\bm{r}_i - \bm{r}_k)(\bm{r}_k - \bm{r}_j)}{r_{ik}r_{kj}}u'(r_{ik})u'(r_{kj})$ sum which is computed for each particle. Each iteration, which is the only term that has a computational complexity of $O(n^3)$ every iteration. To optimise this, we note that the sum can be regarded as a 


%%
In this section we present the implementation we used to derive next section's results. 
%
We start by deriving an analytic expression for the local energy. 
\subsection{Analytical Solutions}
%
%
We observe that the considered Hamiltonian contains the Laplace operator, which can be approximated by the method of finite differences.
%
However, we note that the used quantities are the local energy $E_L$ and the quantum force $F$, which can be described analytically and therewith save computational time. 
%
We start by deriving the local energy in the harmonic oscillator potential, i.e., $a=0$ implying $f(a,|r_i-r_j|)=1$ and $V_{\mathrm{int}}(|r_i-r_j|)=0$.
%
\subsubsection{Harmonic Oscillator Potential}
Following, we start with $\beta =1$, i.e., $g(\alpha, \beta, r_i)=\exp(-\alpha r_i^2)$ and find the relevant local energies in one, two and three dimensions for one and $N$ particles with the same mass. 
%
The trial function of a one dimensional single particle is given by
\begin{align*}
\psi_T(r_1,\alpha,1) = \exp(-\alpha r_1^2)~.
\end{align*}
We then compute 
\begin{align*}
H\psi_T(r_1,\alpha,1)
&=
\left(\frac{-\hbar^2}{2m}\Delta +\frac{1}{2}m\omega_{ho}^2r_1^2\right)\exp(-\alpha r_1^2)\\
&=
-\frac{\hbar^2}{2m}\left(4\alpha^2r_1^2-2\alpha\right)\exp(-\alpha r_1^2)+V_{\mathrm{ext}}(r_1)\exp(-\alpha r_1^2)~,
\end{align*}
which yields 
\begin{align*}
E_L(r_1,\alpha)
=
-\frac{\hbar^2}{2m}\left(4\alpha^2r_1^2-2\alpha\right)+V_{\mathrm{ext}}(r_1)~.
\end{align*}
Note that in atomic unites with $\alpha=1/2$ the local energy is given by $E_L = 1/2$, which is the ground-state energy of the one dimensional harmonic oscillator.
% 
This can be straightforwardly generalized to the $n$-dimensional case, where
\begin{align*}
H\psi_T(r_1,\alpha,1)
&=
-\frac{\hbar^2}{2m}\left(4\alpha^2r_1^2-2\alpha n\right)\exp(-\alpha r_i^2)+V_{\mathrm{ext}}(r_1)\exp(-\alpha r_1^2)
\end{align*}
and therewith
\begin{align*}
E_L(r_1,\alpha)
=
-\frac{\hbar^2}{2m}\left(4\alpha^2r_1^2-2\alpha n\right)+V_{\mathrm{ext}}(r_1)~.
\end{align*}
For $N$ particles in $n$ dimensions the trial function reads
\begin{align*}
\psi_T(r_1,...,r_N,\alpha,1)
=
\prod_{i=1}^N\exp\big(-\alpha r_i^2\big)
=
\exp\big(-\alpha \sum_{i=1}^Nr_i^2\big)~.
\end{align*}
Similar to the one dimensional case we then compute
\begin{align*}
H\psi_T(r_1,...,r_N,\alpha,1)
=
\left(\sum_{i=1}^N-\frac{\hbar^2}{2m}\left(4\alpha^2r_i^2-2\alpha n\right)
+V_{\mathrm{ext}}(r_i)\right)\psi_T(r_1,...,r_N,\alpha,1)
\end{align*}
and therewith 
\begin{align*}
E_L(r_1,...,r_N,\alpha)
=
\sum_{i=1}^N-\frac{\hbar^2}{2m}\left(4\alpha^2r_i^2-2\alpha n\right)
+V_{\mathrm{ext}}(r_i)~.
\end{align*}
Assuming $\beta\neq 1 $ only influences the three dimensional case. 
%
We compute for one particle
\begin{align*}
H \psi_T(r_1,\alpha,\beta)
=
-\frac{\hbar^2}{2m}\left(4\alpha^2(x^2+y^2+\beta^2z^2)-2\alpha (2+\beta)\right)\psi_T(r_1,\alpha,\beta)+V_{\mathrm{ext}}(r_1)\psi_T(r_1,\alpha,\beta)~,
\end{align*}
with the trial function
\begin{align*}
\psi_T(r_1,\alpha,1) = \exp(-\alpha (x^2+y^2+\beta z^2))~.
\end{align*}
Hence,
\begin{align*}
E_{L}(r_1,\alpha,\beta)
=
-\frac{\hbar^2}{2m}\left(4\alpha^2(x^2+y^2+\beta^2z^2)-2\alpha (2+\beta)\right)+V_{\mathrm{ext}}(r_1)~.
\end{align*}
We conclude for the $N$- particle case for the trial function
\begin{align*}
\psi_T(r_1,...,r_N,\alpha,\beta) = \exp(-\alpha \sum_{i=1}^{N}(x_i^2+y_i^2+\beta z_i^2))
\end{align*}
that
\begin{align*}
H \psi_T(r_1,...,r_n,\alpha,\beta)
&=
\sum_{i=1}^N-\frac{\hbar^2}{2m}\left(4\alpha^2(x_i^2+y_i^2+\beta^2z_i^2)-2\alpha (2+\beta)\right)\psi_T(r_1,...,r_n,\alpha,\beta)\\
&\quad +V_{\mathrm{ext}}(r_i)\psi_T(r_1,...,r_n,\alpha,\beta)~,
\end{align*}
and therewith
\begin{align*}
E_L(r_1,...,r_n,\alpha,\beta)
&=
\sum_{i=1}^N-\frac{\hbar^2}{2m}\left(4\alpha^2(x_i^2+y_i^2+\beta^2z_i^2)-2\alpha (2+\beta)\right)+V_{\mathrm{ext}}(r_i)~.
\end{align*}

\subsubsection{Quantum Force for the Harmonic Oscillator Potential}
%
%
Another often used quantity is th drift coefficient of the Fokker--Planck equation, i.e., the quantum force $F$. 
%
As we do not want to approximate the gradient of the trial function for every sampling, we derive the expression analytically for the harmonic oscillator potential with $\beta =1$.
%
Then the trial function is again given by    
\begin{align*}
\psi_T(r_1,\alpha,1) = \exp(-\alpha r_1^2)~,
\end{align*}
for which the quantum force is
\begin{align*}
F(r_1,\alpha,1) = \frac{1}{\psi_T(r_1,\alpha,1)}\nabla \psi_T(r_1,\alpha,1)
=
-2\alpha r_1~.
\end{align*}
As the gradient is a map $\nabla:L^2(\mathbb{R}^{3N})\to \big(L^2(\mathbb{R}^{3N})\big)^{3N}$ (using its weak formulation), we obtain the following quantum force for the $N$-particle case
\begin{align*}
F(r_1,...,r_N,\alpha,1) = \frac{1}{\psi_T(r_1,...,r_N,\alpha,1)}\nabla \psi_T(r_1,...,r_N,\alpha,1)
=
-2\alpha (r_i)_{i=1}^N~,
\end{align*}
where $(r_i)_{i=1}^N = (x_1, y_1 , z_1, x_2,...., z_N)^T$.

\subsubsection{The Local Energy in the full Potential}
%
%
Next we consider the full problem in three dimensions.
%
The aim is to find an analytic expression for the derivative of the trial wave function

\begin{equation*}
\frac{1}{\Psi_T({r})}\sum_i^{N}\nabla_i^2\Psi_T({r})~,
\end{equation*}
with the trial function given by Eq.~\eqref{eq:trialwf}.
%
Rewriting this trial function yields
\begin{align*}
\psi_T(r_1,...,r_N,\alpha,\beta)=\prod_{i=1}^N g(\alpha,\beta,{r}_i)\exp{\left(\sum_{i<j}u(r_{ij})\right)}~,
\end{align*}
where we have defined $r_{ij}=|{r}_i-{r}_j|$ and 
\begin{align*}
f(r_{ij})= \exp{\left(\sum_{i<j}u(r_{ij})\right)}~,
\end{align*}
where $u:\mathbb{R}\to \mathbb{R}$ with $x\mapsto \ln \left(1-\frac{a}{x}\right)$.
%
Using the product rule we find
\begin{equation}
\label{eq:gradientTrialFunk}
\begin{aligned}
\nabla_k\psi_T(r_1,...,r_N,\alpha,\beta)
&=
\left(\nabla_kg(\alpha,\beta,{r}_k)\right)\prod_{i\neq k;i=1}^N g(\alpha,\beta,{r}_i)\exp{\left(\sum_{i<j}u(r_{ij})\right)}\\
&\quad +\prod_{i=1}^N g(\alpha,\beta,{r}_i)\exp{\left(\sum_{i<j}u(r_{ij})\right)}\sum_{i<j}^N\nabla_ku(r_{ij})~,
\end{aligned}
\end{equation}
where 
\begin{align*}
\sum_{i<j}^N\nabla_ku(r_{ij})
=
\frac{1}{2}\sum_{j=1}^N\sum_{i\neq j;i=1}^N\nabla_k u(|r_i-r_j|) ~.
\end{align*}
Note that we sightly abuse the notation here, namely $u(|r_i-r_j|)$ describes the map $u(|\cdot -r_j|):\mathbb{R}^3\to \mathbb{R}$ evaluated in $r_i$ as well as the map $u(|r_i -\cdot|):\mathbb{R}^3\to \mathbb{R}$ evaluated in $r_j$.
%
Consequently holds
\begin{align}
\label{eq:nablaU}
\nabla_i u(|r_i-r_j|)
=
u'(|r_i-r_j|)\nabla_i |r_i-r_j|
=
\frac{a(r_i-r_j)}{(|r_i-r_j|-a)|r_i-r_j|^2}=\nabla_i u(|r_j-r_i|)~,
\end{align} 
and therewith
\begin{align*}
\sum_{i<j}^N\nabla_ku(r_{ij})
=\sum_{j\neq k;j=1}^N\nabla_k u(r_{kj})~.
\end{align*}
From Eq.~\eqref{eq:gradientTrialFunk} we can then derive that the quantum force in the full potential is given by
\begin{align*}
F(r_1,...,r_N,\alpha,\beta)
=
2\left(
\Bigg(\frac{\nabla_i g(\alpha,\beta,{r}_i)}{g(\alpha,\beta,{r}_i)}\Bigg)_{i=1}^N
+
\Bigg(\sum_{j\neq i}\nabla_i u(|r_i-r_j|) \Bigg)_{i=1}^N
\right)~.
\end{align*}
Deriving another time, we find
\begin{equation}
\label{eq:LaplaceTrialFunk}
\begin{aligned}
&\Delta_k\psi_T(r_1,...,r_N,\alpha,\beta)
=
\left(\Delta_kg(\alpha,\beta,{r}_k)\right)\prod_{i\neq k;i=1}^N g(\alpha,\beta,{r}_i)\exp{\left(\sum_{i<j}u(r_{ij})\right)}\\
&\quad +
\left(\nabla_kg(\alpha,\beta,{r}_k)\right)\prod_{i\neq k;i=1}^N g(\alpha,\beta,{r}_i)\exp\left(\sum_{i<j}u(r_{ij})\right)\sum_{j\neq k;j=1}^N\nabla_k u(r_{kj})\\
&\quad +
\prod_{i=1}^N g(\alpha,\beta,{r}_i)\exp{\Bigg(\sum_{i<j}u(r_{ij})\Bigg)}\Bigg(\sum_{j\neq k;j=1}^N\nabla_k u(r_{kj})\Bigg)^2\\
&\quad +
\prod_{i=1}^N g(\alpha,\beta,{r}_i)\exp{\Bigg(\sum_{i<j}u(r_{ij})\Bigg)}\sum_{j\neq k;j=1}^N\Delta_k u(r_{kj})~.
\end{aligned}
\end{equation}
As for the local energy this needs to be divided by the trial function, we find the following expression for the second derivative
\begin{equation}
\label{eq:LaplaceTrialFunkQuot}
\begin{aligned}
&\frac{\Delta_k\psi_T(r_1,...,r_N,\alpha,\beta)}{\psi_T(r_1,...,r_N,\alpha,\beta)}
=
\frac{\Delta_kg(\alpha,\beta,{r}_k)}{g(\alpha,\beta,{r}_k)}
+
\frac{\nabla_kg(\alpha,\beta,{r}_k)}{g(\alpha,\beta,{r}_k)}\sum_{j\neq k;j=1}^N\nabla_k u(r_{kj})\\
&\quad +
\sum_{i,j\neq k}\nabla_k u(r_{kj})\nabla_k u(r_{kj})
+
\sum_{j\neq k;j=1}^N\Delta_k u(r_{kj})~,
\end{aligned}
\end{equation}
with 
\begin{align*}
\Delta_ku(r_{kj})
&=
\nabla_k\cdot \frac{r_k-r_j}{|r_k-r_j|}u'(|r_k-r_j|)\\
&=
u''(|r_k-r_j|)
+
u'(|r_k-r_j|)\Bigg(
\frac{3}{|r_k-r_j|}
-(r_k-r_j)\cdot\frac{(r_k-r_j)}{|r_k-r_j|^3}
\Bigg)\\
&=
u''(|r_k-r_j|)
+
u'(|r_k-r_j|)
\frac{2}{|r_k-r_j|}~.
\end{align*}
It remains to compute $u'$ and $u''$.
%
We already computed $u'$ in Eq.~\eqref{eq:nablaU}, however, for the sake of completeness we list it again subsequently.
%
We find
\begin{align*}
u'(r_{ij})&=\frac{a}{(r_{i,j}-a)r_{i,j}}~,\\
u''(r_{ij})&=-\frac{a}{((r_{i,j}-a)r_{i,j})^2}(2r_{ij}-a)~.
\end{align*} 
This together with the analytic expression for the harmonic oscillator yields an analytic expression or the local energy.


\subsection{The Repulsive Interaction}
\subsubsection{Change units of Length}
%
We here consider a different unit of length, namely, $r\to r/a_{ho}$.
%
This corresponds to introducing the energy in units of $\hbar \omega_{ho}$, i.e., the Hamiltonian transforms as $H\to H/\hbar. \omega_{ho}$
%
The transformed Hamiltonian reads
\begin{align}
\label{eq:repulsiveHam}
\frac{1}{\hbar \omega_{ho}}H
=
\frac{1}{\hbar \omega_{ho}}\sum_{i=1}^{N}\frac{1}{2}\bigg(
-\frac{\hbar^2}{m}\nabla_i^2+m\omega_{ho}^2(x_i^2+y_i^2)+m\omega_z^2z_i^2
\bigg)
+
\frac{1}{\hbar \omega_{ho}}V_{\mathrm{int}}(|r_i-r_j|)~.
\end{align} 
As $V_{\mathrm{int}}$ is either zero or infinity it follows that 
\begin{align*}
\frac{1}{\hbar \omega_{ho}}V_{\mathrm{int}}(|r_i-r_j|) = V_{\mathrm{int}}(|r_i-r_j|)~.
\end{align*}
We recall that 
\begin{align*}
a_{ho} = \bigg(\frac{\hbar}{m\omega_{ho}}\bigg)^{1/2}
\end{align*}
and simplify Eq.~\eqref{eq:repulsiveHam} as follows
\begin{align*}
\frac{1}{\hbar \omega_{ho}}H
&=
\sum_{i=1}^{N}\frac{1}{2}\bigg(
-\frac{\hbar}{m\omega_{ho}}\nabla_i^2+\frac{m\omega_{ho}}{\hbar}(x_i^2+y_i^2)+\frac{m}{\hbar \omega_{ho}}\frac{\omega_{ho}}{ \omega_{ho}}\omega_z^2z_i^2
\bigg)
+
V_{\mathrm{int}}(|r_i-r_j|)\\
&=
\sum_{i=1}^{N}\frac{1}{2}\bigg(
-a_{ho}^2\nabla_i^2+a_{ho}^{-2}(x_i^2+y_i^2)+a_{ho}^{-2}\frac{\omega_z^2}{\omega_{ho}^2}z_i^2
\bigg)
+
V_{\mathrm{int}}(|r_i-r_j|)~.
\end{align*} 
Indeed, this corresponds to the change of length unit $r\to r/a_{ho}$.
%
The Hamiltonian then reads
\begin{align*}
H
=
\sum_{i=1}^{N}\frac{1}{2}\bigg(
-\nabla_i^2+x_i^2+y_i^2+\gamma^2 z_i^2
\bigg)
+
V_{\mathrm{int}}(|r_i-r_j|)~,
\end{align*} 
where we introduced the constant $\gamma = \omega_z/\omega_{ho}$.





% Analysis of results:
%Here you should discuss your main findings, link them up with existing literature, discuss 
%eventual errors, the effectiveness of your algorithm, stability of the calculations etc. 
%Total number of possible points: 20
\section{Numerical Results}



%Conclusions and perspectives: 
%Here you give a summary of your discussions and critical comments, what was learned about the method(s) 
%you used and on the results obtained. If possible, try to present some perspectives for future work,
%Possible directions and future improvements.  
%Total number of possible points: 10
\section{Conclusion and Perspectives}


%Clarity of figures, tables and overall presentation. 
%Remember proper table and figure captions. Label all lines properly and remember labels on your axes.
%If specific units are used, these should be stated.
%Total number of possible points: 10


%References: 
%You should cite relevant works accurately. As an example, for journal articles use
%Author(s), Journal name, volume, pages and year (you can include title as well and possible weblink).
%For books, use Author(s), title of book, publisher, year and eventually which pages. 
%Total number of possible points: 5

\pagebreak
\bibliographystyle{unsrt}
\bibliography{lib}




\end{document}

